\begin{abstract}

Designing end-to-end systems which combine different robotic tasks (e.g. natural language and planning) is a challenging problem. Most robotics projects perform particular task and are difficult to combine and generalise across different environments, modalities and require different kinds of human involvement like hand crafting features and/or different feedback mechanisms.
We are aiming to build a joint system for Natural Language grounding to human-context aware trajectory generation, which can be improved via single weak user-feedback mechanism. The feedback is given on the end-to-end system rather than the individual systems.
Experiments show that we can achieve performance close to the expert systems via much simpler feedback and using much less number of examples.

\end{abstract}

