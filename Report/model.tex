% !TEX root = main.tex
\section{Problem Formulation}
In this section we formally describe the learning procedure. We consider modules $M_1,M_2,...,M_N$ connected to form a cascade. Input into  module $M_i$ is denoted by $x_i$ and its output by $y_i$.  Modules are connected such that the output of $M_{i-1}$ forms the input into $M_i$, i.e. $y_{i-1} = x_i$. Each module further defines a function $f_i(x_i,y_i;\theta_i)$ jointly over its input $x_i$ and output $y_i$, and parametrized by $\theta_i$. The input into the cascade is task $x_1$, and the output robot behaviour presented to the user is $y_N$. 	We further assume a function $U(x_{i},y_{i})$ which conveys how much the user values output $y_{i}$ for input $x_{i}$ at a particular module $i$. We further assume a function $U(x_1,y_N)$ which conveys the performance of the entire system, though such a function is never observed. The algorithm only gets to observe user feedback on $y_N$ and none of the $y_{i}$'s are known. We have designed a heuristic that maps the output $y_{N}$ to the output sequence $y_{i}$ for different modules and learn their parameters. Our learning setting iteratively performs the following steps:
\begin{enumerate}
\item At each iteration $t$, the robot is presented with a task $x_1$ and it generates behaviour $y_{N,t}$ which is presented to the user
\item The user provides a feedback $\bar{y}_{N,t}$ by improving upon ${y}_{N,t}$ such that $U(x_1,\bar{y}_{N,t}) > U(x_1,{y}_{N,t})$
\item Heuristic maps the feedback $y_{N}$ to the sequence of output $\bar{y}_{1}, \bar{y}_{2} \dots \bar{y}_{N-1}$ for different modules
\item The parameters $\{\theta_1,...,\theta_N\}$ of the entire cascade are updated using the utility functions $U(x_{i},y_{i})$ and the mapped output
\end{enumerate} 

The learning setting with the designed heuristic described above extends coactive learning~\citep{Jain13,Shivaswamy12} to a system with multiple modules and a single feedback. Upon receiving the user feedback, parameters of module $M_i$ are updated using the following perceptron equation:  
\begin{align}
\theta_i \leftarrow \theta_i +  \frac{\partial U_i(x_i,\bar{y}_i)}{\partial \theta_i} &- \frac{\partial U_i(x_i,{y}_i)}{\partial \theta_i}
\end{align}
% In the above equations the	 gradient $\frac{\partial f_N(x_N,\bar{y}_N)}{\partial \theta_i}$ is calculated using backpropagation as follows:
% \begin{align}
% \frac{\partial f_N(x_N,\bar{y}_N)}{\partial \theta_i} &= \frac{\partial y_i}{\partial \theta_i}  \frac{\partial f_N(x_N,\bar{y}_N)	}{\partial y_{i}}\\
% \frac{\partial f_N(x_N,\bar{y}_N)	}{\partial y_{i}} &= \frac{\partial y_{i+1}	}{\partial y_{i}} \frac{\partial f_N(x_N,\bar{y}_N)	}{\partial y_{i+1}}
% \end{align}
By mapping the feedback to different modules of the cascade using the designed heuristic, we incorporate the corrective user feedback to update each module in the cascade. The progress made by the learning algorithm is measured by its regret which is given by the following equation:%~\eqref{eq:regret} which cannot be directly observed.
\begin{equation}
\label{eq:regret}
REG_T = \frac{1}{T}\sum_{t=1}^T U(x_{1,t},y_{N,t}^*) - U(x_{1,t},y_{N,t}) 
\end{equation}
Here $y_{N,t}^*$ is the optimal robot behaviour for $x_{1,t}$, and $y_{N,t}$ is the behaviour predicted by the algorithm at iteration $t$. The regret cannot be directly observed as $y_{N,t}^*$ and utility $U$ are not observable. However, if the user at each iteration incrementally improves upon $y_N$ then the regret asymptotically decays to zero under mild constraints~\citep{Shivaswamy12,Jain13}.

\subsection{Pseudo Code}

\textbf{Input:} Environment Env, NL Sentence N, tellmedaveWeights ($W_{T}$), planitWeights($W_{P}$)
\newline \newline
\textit{Step1 (generating user feedback)} \newline \newline
ActionSeq=TellMeDave(Env,N,tellmedaveWeights)  
moveActionSeq=Filter(ActionSeq)  \newline  \newline
for intermediateObject in moveActionSeq:
\begin{enumerate}
\item path=generatePath(Env,intermediateObject,planitWeights)
\item playInSimulator(Env,path)
\item stop trajectory and capture the current point
\item user moves the current point and records the updated point
\item feedback.add((currentPoint,updatedPoint))
\end{enumerate}
\pagebreak
% \vspace{6em}
\textit{Step2(updating parameters)} \newline \newline
option=MapFeedback(feedback) \newline
if (option == 'planit') \newline
\{ \newline
\hphantom {1}for feed in feedback : \newline
\hphantom {1} \hphantom {1} $\bar{W}_{P}$=updatePlanit(feed,$W_{P}$) \newline
\} \newline
else \newline
\{ \newline
\hphantom {1}feed=mapToTopKOutput(feedback)
\hphantom {1}$\bar{W}_{T}$=updateTellMeDave(feed,$W_{T}$,Env) \newline
\} \newline \newline
\textit{Step3} \newline 
return planitWeights,tellmedaveWeights \newline